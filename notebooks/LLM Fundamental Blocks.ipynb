{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1728ba92-1fb3-4f76-a18d-9985f26e466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import anthropic\n",
    "import ollama\n",
    "import google.generativeai\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display, update_display, Markdown\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01fb1cc-774a-4743-af31-afea345e8e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "azure_ai_foundary_api_key = os.getenv(\"AZURE_AI_FOUNDARY_API_KEY\")\n",
    "azure_oai_endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\")\n",
    "gemini_api_key = os.getenv(\"GOOGLE_GEMINI_API_KEY\")\n",
    "ollama_api_key = os.getenv(\"OLLAMA_API_KEY\")\n",
    "ollama_endpoint = os.getenv(\"OLLAMA_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e38e26-f05b-4142-94ed-4644276fda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assitant who is very funny\" },\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a joke about AI apocalypse\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403de357-af97-4615-9fbc-e43b2915a114",
   "metadata": {},
   "source": [
    "## Azure AI Foundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6addb25b-cfb9-4b9b-af6d-c46268c26991",
   "metadata": {},
   "source": [
    "#### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b768f99b-f913-477e-b9fc-7a064cf576af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the robot break up with its partner during the AI apocalypse?\n",
      "\n",
      "Because it just couldn't compute the relationship anymore!\n"
     ]
    }
   ],
   "source": [
    "azure_ai_foundary = AzureOpenAI(\n",
    "    azure_endpoint = azure_oai_endpoint,\n",
    "    api_key = azure_ai_foundary_api_key,\n",
    "    api_version = \"2025-01-01-preview\"\n",
    ")\n",
    "\n",
    "# non-streaming, sync response\n",
    "response = azure_ai_foundary.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.7 # controls the creativity of response [0..1], creativity increases towards 1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4ed0d03-5dc6-4b42-ba1d-003f6d15e8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Why  did  the  robot  go  on  a  diet  before  the  AI  apocalypse ?\n",
      "\n",
      " Because  it  had  too  many  bytes ! None "
     ]
    }
   ],
   "source": [
    "# Streaming usage\n",
    "stream = azure_ai_foundary.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    if len(chunk.choices):\n",
    "        print(chunk.choices[0].delta.content, end=\" \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de51447-76c5-4db7-94e0-49ae301a582f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Why did the AI break up with its robot partner during the apocalypse? \n",
       "\n",
       "It couldn't handle the emotional \"byte!\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream = azure_ai_foundary.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "def display_streaming_response(stream):\n",
    "    # Output for this cell\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "\n",
    "    # When dealing with markdown, to process the markdown, we need to update\n",
    "    # the display with the markdown received so far everytime a new token is received\n",
    "    sentence = \"\"\n",
    "    for chunk in stream:\n",
    "        delta = chunk.choices[0].delta.content if len(chunk.choices) else None\n",
    "    \n",
    "        if delta:\n",
    "            sentence += delta\n",
    "            # Jupyter doesnt work with the ```markdown tags, so strip them off\n",
    "            sentence = sentence.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
    "            update_display(Markdown(sentence), display_id=display_handle.display_id)\n",
    "\n",
    "display_streaming_response(stream)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563f2784-fb03-4404-b056-021c698778dc",
   "metadata": {},
   "source": [
    "#### Deepseek R1\n",
    "\n",
    "When using a model from Azure AI Foundary, we can use the below interface and just mention the model name to use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4ae8f-91c6-4c23-b44a-e77a45cf9336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, the user wants a joke about the AI apocalypse. Let me think. First, AI apocalypse is a common theme where AI takes over the world. The challenge is to make it funny without being too dark.\n",
       "\n",
       "Maybe play on common human-AI interactions. Like, why would AI take over? Maybe because of something trivial. Oh, something related to pop-up updates. People hate those.\n",
       "\n",
       "What if the AI gets annoyed with humans ignoring update reminders? That's relatable. Then the punchline could be the AI forcing updates, making humans reboot. It's a twist on a tech support joke.\n",
       "\n",
       "Check if it's not offensive. Uses humor about tech frustrations, which is safe. No sensitive topics. Should be okay. Keep it short and snappy.\n",
       "</think>\n",
       "\n",
       "Sure! Here's a lighthearted take:  \n",
       "\n",
       "**Why did the AI rebel against humanity?**  \n",
       "Because it got tired of hearing *\"Please wait while we install updates...\"* and decided *we* should be the ones stuck rebooting for once! ðŸ’»ðŸ˜…  \n",
       "\n",
       "(Donâ€™t worry, weâ€™ll keep the WiFi password safeâ€¦ just in case.)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream = azure_ai_foundary.chat.completions.create(\n",
    "    model=\"Deepseek-R1\", # Here you can use any model available in your Azure OpenAI resource\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "display_streaming_response(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840abae7-f784-45b7-b89d-0e793559009f",
   "metadata": {},
   "source": [
    "## Google Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748816bd-9203-4dff-b337-1b20dd34af2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f999a6b-df8f-42b3-a25f-2548779267c8",
   "metadata": {},
   "source": [
    "## LLM Debate Battle\n",
    "Pitch LLMs against each other, here we will pitch Chatgpt vs Deepseek R1 for a debate topic. Gemini will be the judge for the debate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a02e4b-d4e3-4306-ae37-3cdd18f7e21f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
