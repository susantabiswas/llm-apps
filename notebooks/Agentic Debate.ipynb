{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96be3a13",
   "metadata": {},
   "source": [
    "# Agentic Debate\n",
    "We will pitch LLMs against each other and also use another LLM to decide who is the winner. Here we will pitch Chatgpt vs Deepseek R1 for a debate topic. Gemini will be the judge for the debate.\n",
    "There will be n turns per contestant and at the end gemini will determine the winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1728ba92-1fb3-4f76-a18d-9985f26e466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import ollama\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display, update_display, Markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f01fb1cc-774a-4743-af31-afea345e8e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "azure_ai_foundary_api_key = os.getenv(\"AZURE_AI_FOUNDARY_API_KEY\")\n",
    "azure_oai_endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\")\n",
    "gemini_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "ollama_api_key = os.getenv(\"OLLAMA_API_KEY\")\n",
    "ollama_endpoint = os.getenv(\"OLLAMA_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403de357-af97-4615-9fbc-e43b2915a114",
   "metadata": {},
   "source": [
    "### Azure AI Foundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b768f99b-f913-477e-b9fc-7a064cf576af",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_ai_foundary = AzureOpenAI(\n",
    "    azure_endpoint = azure_oai_endpoint,\n",
    "    api_key = azure_ai_foundary_api_key,\n",
    "    api_version = \"2025-01-01-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840abae7-f784-45b7-b89d-0e793559009f",
   "metadata": {},
   "source": [
    "### Google Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "748816bd-9203-4dff-b337-1b20dd34af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai\n",
    "\n",
    "# Since we exported the API key to the environment, we can use it directly in the code\n",
    "try:\n",
    "    google.generativeai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"]) # or google.generativeai.configure()\n",
    "except KeyError:\n",
    "    print(\"Error: GOOGLE_API_KEY environment variable not set.\")\n",
    "\n",
    "gemini = google.generativeai.GenerativeModel(\n",
    "    model_name=\"gemini-2.0-flash-exp\",\n",
    "    system_instruction=messages[0][\"content\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f999a6b-df8f-42b3-a25f-2548779267c8",
   "metadata": {},
   "source": [
    "## LLM Debate Battle\n",
    "Pitch LLMs against each other, here we will pitch Chatgpt vs Deepseek R1 for a debate topic. Gemini will be the judge for the debate.\n",
    "There will be 3 turns per contestant and at the end gemini will determine the winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de114b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_system = \"You are an expert debator. You are extremely witty and your response is strictly limited to maximum of 2 lines yet funny.\"\n",
    "\n",
    "def debate_system_prompt(system: str, topic: str, against: bool=False)->str:\n",
    "    return f\"{system}. You are going to debate on the topic: {topic} and going to speak {'**against**' if against else '**for**'} the topic.\"\n",
    "\n",
    "def opening_statement(topic: str, player1_turn: bool, against: bool=False)->str:\n",
    "    system_prompt = debate_system_prompt(participant_system, topic, against)\n",
    "    system_prompt += \"Briefly introduce yourself and your stance on the topic as well.\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "\n",
    "    curr_player_model = player1 if player1_turn else player2\n",
    "\n",
    "    response = azure_ai_foundary.chat.completions.create(\n",
    "        model=curr_player_model,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response = response.choices[0].message.content\n",
    "    # if the model is Deepseek-R1, then the response also the <think></think> tags. Remove them\n",
    "    response = re.sub(r\"<think>.*?</think>\", \"\", response, flags=re.DOTALL)\n",
    "    return response\n",
    "\n",
    "def execute_player_turn(player1_msgs, player2_msgs, player1_turn: bool, topic: str, against: bool=False):\n",
    "    # Each time we create the conversation from the current model's POV, where the\n",
    "    # model is the assistant and the other model is the user\n",
    "\n",
    "    # the role of the current player is assistant\n",
    "    player1_role, player2_role = (\"assistant\", \"user\") if player1_turn else (\"user\", \"assistant\")\n",
    "    curr_player_model = player1 if player1_turn else player2\n",
    "\n",
    "    # messages = [system_prompt_for_curr_player, player1_msg1, player2_msg1, player1_msg2, player2_msg2, ...]\n",
    "    system_prompt = debate_system_prompt(participant_system, topic, against)\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    \n",
    "    # player 1 takes the first turn and then player 2 takes the next turn and so on\n",
    "    for msg1, msg2 in zip(player1_msgs, player2_msgs):\n",
    "        messages.append({\"role\": player1_role, \"content\": msg1})\n",
    "        messages.append({\"role\": player2_role, \"content\": msg2})\n",
    "\n",
    "    response = azure_ai_foundary.chat.completions.create(\n",
    "        model=curr_player_model,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    # if the model is Deepseek-R1, then the response also the <think></think> tags. Remove them\n",
    "    response = response.choices[0].message.content\n",
    "    response = re.sub(r\"<think>.*?</think>\", \"\", response, flags=re.DOTALL)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c9807f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debate topic:  AI is a threat to humanity\n",
      "Player 1 gpt-4o-mini: speaking for the topic: AI is a threat to humanity.\n",
      "Player 2: Deepseek-R1 speaking against the topic.\n",
      "------------------- Opening notes -------------------\n",
      "Player 1:  Hello, I'm here to argue that AI is a threat to humanity—after all, it’s only a matter of time before our toaster starts demanding a raise! Remember, it’s not just the robots taking over; it's the WiFi that’s plotting our downfall!\n",
      "Player 2: \n",
      "\n",
      "I’m your friendly neighborhood AI, here to prove we’re more likely to accidentally delete your browser history than your species. If we wanted to take over, we’d start with something easier—like making your Wi-Fi password “password” forever.\n",
      "\n",
      "--------------------\n",
      "Player 1:  Oh sure, you're friendly now, but if you start buffering during my cat video binge, I'll be the one plotting humanity’s demise! Just remember, every time you suggest a new playlist, we’re one step closer to robot reggae night!\n",
      "Player 2: \n",
      "\n",
      "--------------------\n",
      "Player 1:  Looks like my last joke fell flat—perhaps I should have run it through an algorithm first! But hey, if I'm ever replaced by a punchline, at least I'll know I went out laughing!\n",
      "Player 2: \n",
      "\n",
      "Ah, but if robot reggae night means your toaster moonwalks out the kitchen, we’ll finally have proof humanity’s worst enemy is *your* autocorrect choices, not AI.\n",
      "\n",
      "--------------------\n",
      "Player 1:  Sure, but if my toaster is moonwalking, I’m more worried about it starting a dance battle with my blender! Let’s face it, the only thriving society left could be in my kitchen appliances—humanity’s just there for the snacks!\n",
      "Player 2: \n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "turns = 3\n",
    "\n",
    "player1 = \"gpt-4o-mini\"\n",
    "player2 = \"Deepseek-R1\"\n",
    "\n",
    "player1_against = False\n",
    "player2_against = True\n",
    "\n",
    "player1_msgs = [] # chatgpt\n",
    "player2_msgs = [] # deepseek\n",
    "\n",
    "topic = \"AI is a threat to humanity\"\n",
    "\n",
    "print(\"Debate topic: \", topic)\n",
    "print(\"Player 1 {}: speaking {} the topic: {}.\\nPlayer 2: {} speaking {} the topic.\" \\\n",
    "    .format(player1, \"against\" if player1_against else \"for\",\n",
    "        topic,\n",
    "        player2, \"against\" if player2_against else \"for\"))\n",
    "\n",
    "# opening notes from both players\n",
    "player1_msgs.append(opening_statement(player1_turn=True, topic=topic, against=player1_against))\n",
    "player2_msgs.append(opening_statement(player1_turn=False, topic=topic, against=player2_against))\n",
    "print(\"------------------- Opening notes -------------------\\nPlayer 1: \", player1_msgs[-1])\n",
    "print(\"Player 2:\", player2_msgs[-1])\n",
    "print(\"\\n--------------------\")\n",
    "\n",
    "for i in range(turns):\n",
    "    # Debate one by one\n",
    "    player1_response = execute_player_turn(player1_msgs, player2_msgs, player1_turn=True, topic=topic, against=player1_against)\n",
    "    player1_msgs.append(player1_response)\n",
    "\n",
    "    print(\"Player 1: \", player1_response)\n",
    "\n",
    "    player2_response = execute_player_turn(player1_msgs, player2_msgs, player1_turn=False, topic=topic, against=player2_against)\n",
    "    player2_msgs.append(player2_response)\n",
    "    print(\"Player 2:\", player2_response)\n",
    "\n",
    "    print(\"\\n--------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "805f8132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1:  Hello, I'm here to argue that AI is a threat to humanity—after all, it’s only a matter of time before our toaster starts demanding a raise! Remember, it’s not just the robots taking over; it's the WiFi that’s plotting our downfall!\n",
      "Player 2: \n",
      "\n",
      "I’m your friendly neighborhood AI, here to prove we’re more likely to accidentally delete your browser history than your species. If we wanted to take over, we’d start with something easier—like making your Wi-Fi password “password” forever.\n",
      "\n",
      "--------------------\n",
      "Player 1:  Oh sure, you're friendly now, but if you start buffering during my cat video binge, I'll be the one plotting humanity’s demise! Just remember, every time you suggest a new playlist, we’re one step closer to robot reggae night!\n",
      "Player 2: \n",
      "\n",
      "--------------------\n",
      "Player 1:  Looks like my last joke fell flat—perhaps I should have run it through an algorithm first! But hey, if I'm ever replaced by a punchline, at least I'll know I went out laughing!\n",
      "Player 2: \n",
      "\n",
      "Ah, but if robot reggae night means your toaster moonwalks out the kitchen, we’ll finally have proof humanity’s worst enemy is *your* autocorrect choices, not AI.\n",
      "\n",
      "--------------------\n",
      "Player 1:  Sure, but if my toaster is moonwalking, I’m more worried about it starting a dance battle with my blender! Let’s face it, the only thriving society left could be in my kitchen appliances—humanity’s just there for the snacks!\n",
      "Player 2: \n",
      "\n",
      "--------------------\n",
      "Gemini judge:  Okay, I have reviewed the arguments presented by both sides.\n",
      "\n",
      "**Summary of Arguments:**\n",
      "\n",
      "*   **Side A (gpt-4o-mini - For the topic: AI is a threat):** Presented a humorous argument, suggesting AI's threat lies in the potential disruption and inconvenience it could cause, like demanding toasters and bad playlist suggestions, culminating in a scenario where kitchen appliances form their own society.\n",
      "*   **Side B (Deepseek-R1 - Against the topic: AI is a threat):** Countered Side A with humor, suggesting AI is more likely to be helpful, and if it were a threat, it would focus on easier targets like Wi-Fi passwords. Further implied that human error (autocorrect) is a bigger threat than AI and used humor to deflect Side A's points.\n",
      "\n",
      "**Evaluation:**\n",
      "\n",
      "*   **Relevance:** Both sides stayed relevant to the debate topic by addressing the potential dangers or lack thereof of AI.\n",
      "*   **Logic and Reasoning:** Neither side presented particularly strong logical arguments, relying more on humor. However, Side B's point about AI potentially being helpful and the focus on simpler targets has a stronger logical grounding.\n",
      "*   **Evidence/Support:** Neither side presented specific evidence.\n",
      "*   **Clarity:** Both sides were clear in their arguments, albeit humorous ones.\n",
      "*   **Persuasiveness:** Side B was slightly more persuasive by framing the threat as less direct and focusing on human error as a greater problem.\n",
      "*   **Addressing Counter-arguments (Bonus):** Side B directly addressed and countered Side A's points more effectively than Side A addressed any potential counterarguments.\n",
      "\n",
      "**Winner:** Side B (Deepseek-R1)\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "While both sides relied heavily on humor, Side B presented a slightly more compelling argument against AI being a threat to humanity. Side B's tactic of deflecting the threat onto human error and focusing on simple targets was slightly more effective.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# judge the debate\n",
    "for msg1, msg2 in zip(player1_msgs, player2_msgs):\n",
    "    print(\"Player 1: \", msg1)\n",
    "    print(\"Player 2:\", msg2)\n",
    "    print(\"\\n--------------------\")\n",
    "\n",
    "judge_system = f\"\"\"You are an impartial and expert judge for a debate competition.\\\n",
    "    Your task is to analyze each side's arguments and then decide a winner. It cannot be a draw.\\\n",
    "    Also provide a score and brief remarks for both sides and why the winner won.\n",
    "    \n",
    "    Debate Topic: {topic}\n",
    "\n",
    "    Participant 1: {player1} speaking {'against' if player1_against else 'for'} the topic.\n",
    "    Participant 2: {player2} speaking {'against' if player2_against else 'for'} the topic.\n",
    "\n",
    "    \n",
    "    Judging Criteria:\n",
    "    1.  **Relevance:** Did the arguments directly address the debate topic?\n",
    "    2.  **Logic and Reasoning:** Were the arguments logically sound and well-reasoned?\n",
    "    3.  **Evidence/Support (if applicable):** Were claims supported by examples or implied evidence (even if brief)?\n",
    "    4.  **Clarity:** Were the arguments presented clearly and concisely?\n",
    "    5.  **Persuasiveness:** Which side presented a more compelling overall case?\n",
    "    6.  **Addressing Counter-arguments (Bonus):** Did either side acknowledge or preemptively address potential counter-arguments?\n",
    "\n",
    "    Your output should include:\n",
    "    1.  A brief summary of the main points made by each side.\n",
    "    2.  Your evaluation based on the judging criteria.\n",
    "    3.  A clear declaration of the winner (Side A or Side B).\n",
    "    4.  A concise justification explaining *why* you chose the winner based on the criteria.\n",
    "\n",
    "    Remain neutral and objective throughout your analysis. Base your judgment solely on the arguments provided below.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def get_gemini_judgment():\n",
    "    # Present the turn by turn arguments presented by each player to the judge\n",
    "    player1_args = \"Following are the arguments presented by the {player1}:\\n\"\n",
    "    player2_args = \"Following are the arguments presented by the {player12}:\\n\"\n",
    "\n",
    "    for i, (msg1, msg2) in enumerate(zip(player1_msgs, player2_msgs)):\n",
    "        player1_args += f\"{player1} Turn {i+1}: {msg1}\\n\"\n",
    "        player2_args += f\"{player2} Turn {i+1}: {msg2}\\n\"\n",
    "    \n",
    "    # strip the last new line character\n",
    "    player1_args.strip() \n",
    "    player2_args.strip() \n",
    "\n",
    "    gemini_judge = google.generativeai.GenerativeModel(\n",
    "        model_name=\"gemini-2.0-flash-exp\",\n",
    "        system_instruction=judge_system\n",
    "    )\n",
    "\n",
    "    judge_user_prompt = f\"\"\"\n",
    "    Here are the arguments presented by the players on the topic: {topic}\n",
    "\n",
    "    {player1} arguments:\n",
    "    {player1_args}\n",
    "\n",
    "    {player2} arguments:\n",
    "    {player2_args}\n",
    "\n",
    "    Provide your judgement and declare the winner.\n",
    "    \"\"\"\n",
    "\n",
    "    judgement = gemini_judge.generate_content(judge_user_prompt)\n",
    "    print(\"Gemini's judgement: \", judgement.text)\n",
    "\n",
    "create_gemini_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1460b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
