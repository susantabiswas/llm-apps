{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1728ba92-1fb3-4f76-a18d-9985f26e466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import anthropic\n",
    "import ollama\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display, update_display, Markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01fb1cc-774a-4743-af31-afea345e8e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "azure_ai_foundary_api_key = os.getenv(\"AZURE_AI_FOUNDARY_API_KEY\")\n",
    "azure_oai_endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\")\n",
    "\n",
    "azure_embed_api_key = os.getenv(\"AZURE_EMBED_KEY\")\n",
    "azure_embed_endpoint = os.getenv(\"AZURE_EMBED_ENDPOINT\")\n",
    "\n",
    "azure_audio_api_key = os.getenv(\"AZURE_AUDIO_API_KEY\")\n",
    "azure_audio_endpoint = os.getenv(\"AZURE_AUDIO_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b768f99b-f913-477e-b9fc-7a064cf576af",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_ai_foundary = AzureOpenAI(\n",
    "    azure_endpoint = azure_oai_endpoint,\n",
    "    api_key = azure_ai_foundary_api_key,\n",
    "    api_version = \"2025-01-01-preview\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04599a0e-8be1-42e3-be9f-d8f77a528e3e",
   "metadata": {},
   "source": [
    "## Langchain RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ded2a1ea-d217-4b8e-8ca2-bb52ad9df903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# vector embeddings for vector db\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_azure_ai.chat_models import AzureAIChatCompletionsModel\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "\n",
    "# Debugging intermediate steps of langchain\n",
    "from langchain_core.callbacks import StdOutCallbackHandler\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a7d284-fb36-49ad-be1e-3b3deadfa3be",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "Load all the documents which can be vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "767fbef6-9105-4ce2-909d-0356bcd1f6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder data\\business, doc_type: business\n",
      "Found 5 docs of doc_type: business\n",
      "Folder data\\developers, doc_type: developers\n",
      "Found 4 docs of doc_type: developers\n",
      "Folder data\\projects, doc_type: projects\n",
      "Found 5 docs of doc_type: projects\n",
      "Total docs: 14\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join('data', '*')\n",
    "\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "\n",
    "documents = []\n",
    "folders = glob.glob(data_path)\n",
    "\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "\n",
    "    print(f'Folder {folder}, doc_type: {doc_type}')\n",
    "    loader = DirectoryLoader(folder,\n",
    "                glob=\"**/*.md\", \n",
    "                loader_cls=TextLoader,\n",
    "                loader_kwargs=text_loader_kwargs)\n",
    "\n",
    "    docs = loader.load()\n",
    "    print(f'Found {len(docs)} docs of doc_type: {doc_type}') \n",
    "    for doc in docs:\n",
    "        doc.metadata['doc_type'] = doc_type\n",
    "        documents.append(doc)\n",
    "\n",
    "print(f'Total docs: {len(documents)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e30bca-d934-4b02-b945-f85ce2e4c66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of documents\n",
      "{'source': 'data\\\\business\\\\cloudsync_impact.md', 'doc_type': 'business'}\n",
      "{'source': 'data\\\\business\\\\dataviz_impact.md', 'doc_type': 'business'}\n",
      "{'source': 'data\\\\business\\\\fraud_detection_impact.md', 'doc_type': 'business'}\n",
      "{'source': 'data\\\\business\\\\healthtrack_impact.md', 'doc_type': 'business'}\n",
      "{'source': 'data\\\\business\\\\microservices_impact.md', 'doc_type': 'business'}\n",
      "{'source': 'data\\\\developers\\\\alex_chen.md', 'doc_type': 'developers'}\n",
      "{'source': 'data\\\\developers\\\\john_smith.md', 'doc_type': 'developers'}\n",
      "{'source': 'data\\\\developers\\\\raj_patel.md', 'doc_type': 'developers'}\n",
      "{'source': 'data\\\\developers\\\\sarah_johnson.md', 'doc_type': 'developers'}\n",
      "{'source': 'data\\\\projects\\\\cloudsync.md', 'doc_type': 'projects'}\n",
      "{'source': 'data\\\\projects\\\\dataviz.md', 'doc_type': 'projects'}\n",
      "{'source': 'data\\\\projects\\\\fraud_detection.md', 'doc_type': 'projects'}\n",
      "{'source': 'data\\\\projects\\\\healthtrack.md', 'doc_type': 'projects'}\n",
      "{'source': 'data\\\\projects\\\\microservices.md', 'doc_type': 'projects'}\n"
     ]
    }
   ],
   "source": [
    "# split the documents into chunks, the chunk size and amount of overlaps between the chunks can have\n",
    "# impact on the results\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap= 200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print('List of documents')\n",
    "for chunk in chunks:\n",
    "    print(chunk.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ae560",
   "metadata": {},
   "source": [
    "### Direct Azure OpenAI usage for embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5c179b1-bacf-4250-b880-9aaa8231680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data[0]: length=3072, [0.022330209612846375, -0.002088305074721575, ..., -0.014379994943737984, 0.006100048776715994]\n",
      "data[1]: length=3072, [0.011640272103250027, 0.005252661183476448, ..., -0.028720801696181297, -0.0025770869106054306]\n",
      "data[2]: length=3072, [0.016326788812875748, -0.0018455119570717216, ..., -0.005349587649106979, 0.006049444433301687]\n",
      "Usage(prompt_tokens=6, total_tokens=6)\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "embed_model = AzureOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=azure_embed_endpoint,\n",
    "    api_key=azure_embed_api_key\n",
    ")\n",
    "\n",
    "deployment = \"text-embedding-3-large\"\n",
    "response = embed_model.embeddings.create(\n",
    "    input=[\"first phrase\",\"second phrase\",\"third phrase\"],\n",
    "    model=deployment\n",
    ")\n",
    "\n",
    "for item in response.data:\n",
    "    length = len(item.embedding)\n",
    "    print(\n",
    "        f\"data[{item.index}]: length={length}, \"\n",
    "        f\"[{item.embedding[0]}, {item.embedding[1]}, \"\n",
    "        f\"..., {item.embedding[length-2]}, {item.embedding[length-1]}]\"\n",
    "    )\n",
    "print(response.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a13b923",
   "metadata": {},
   "source": [
    "### Embeddings using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6ab94ba-79fd-47a7-8f57-8c19a4d719f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_llm(env_file: str = None):\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_endpoint=azure_oai_endpoint,\n",
    "        azure_deployment=\"gpt-4o-mini\",\n",
    "        openai_api_version=\"2025-01-01-preview\",\n",
    "    )\n",
    "\n",
    "    embed_model_name = \"text-embedding-3-large\"\n",
    "    embed_api_version = \"2024-12-01-preview\" #\"2024-02-01\"\n",
    "    azure_embed_endpoint = os.environ['AZURE_EMBED_ENDPOINT']\n",
    "\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        model=embed_model_name,\n",
    "        azure_deployment=embed_model_name,\n",
    "        azure_endpoint=azure_embed_endpoint,\n",
    "        openai_api_version=embed_api_version,\n",
    "        api_key=azure_embed_api_key)\n",
    "    \n",
    "    return llm, embeddings\n",
    "\n",
    "llm, azure_embeddings = initialize_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98f548f1-2cee-425d-a0f8-1b79a9caafae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma db path notebooks\\vector_store\\chroma_rag_db\n",
      "db cleared\n",
      "Vectorstore created with 14 documents\n"
     ]
    }
   ],
   "source": [
    "CHROMA_DB = os.path.join(\"notebooks\", \"vector_store\", \"chroma_rag_db\")\n",
    "print(\"Chroma db path\", CHROMA_DB)\n",
    "      \n",
    "# clear the db\n",
    "if os.path.exists(CHROMA_DB):\n",
    "    Chroma(persist_directory=CHROMA_DB, embedding_function=azure_embeddings).delete_collection()\n",
    "    print('db cleared')\n",
    "\n",
    "# vectorize the docs\n",
    "vectorstore = Chroma.from_documents(documents=chunks,\n",
    "                                    embedding=azure_embeddings,\n",
    "                                    persist_directory=CHROMA_DB)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27655178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['0233e4dd-4ab5-4fcd-b616-9ec75396a7ce'], 'embeddings': array([[ 0.00643417, -0.01768304, -0.01689518, ..., -0.01734747,\n",
      "        -0.00097479, -0.01140935]], shape=(1, 3072)), 'documents': None, 'uris': None, 'data': None, 'metadatas': None, 'included': [<IncludeEnum.embeddings: 'embeddings'>]}\n",
      "Dimensions:  3072\n"
     ]
    }
   ],
   "source": [
    "# Inspect the vectorstore\n",
    "collection = vectorstore._collection\n",
    "sample_vector_embed = collection.get(limit=1, include=['embeddings'])\n",
    "print(sample_vector_embed)\n",
    "print('Dimensions: ', len(sample_vector_embed['embeddings'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3a989",
   "metadata": {},
   "source": [
    "### Visualizing Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a530f12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape (14, 3072)\n"
     ]
    }
   ],
   "source": [
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "\n",
    "print('Embedding shape', vectors.shape)\n",
    "documents = result['documents']\n",
    "doc_types = [metadata['doc_type'] for metadata in result['metadatas']]\n",
    "\n",
    "colors_list = ['red', 'blue', 'green', 'orange', 'purple', 'pink', 'brown', 'gray']\n",
    "doc_color_mapping = {}\n",
    "# len(set(doc_types) < len(colors_list), so it wont crash\n",
    "for i, doc_type in enumerate(set(doc_types)):\n",
    "    doc_color_mapping[doc_type] = colors_list[i]\n",
    "\n",
    "colors = [doc_color_mapping[doc_type] for doc_type in doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "365089a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "marker": {
          "color": [
           "green",
           "green",
           "green",
           "green",
           "green",
           "red",
           "red",
           "red",
           "red",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue"
          ],
          "size": 5
         },
         "mode": "markers",
         "text": [
          "Type: business<br>Text: # Business Impact: CloudSync\n\n## Executive Summary\nCloudSync has transformed internal collaboration ...",
          "Type: business<br>Text: # Business Impact: DataViz\n\n## Executive Summary\nDataViz has revolutionized how our enterprise clien...",
          "Type: business<br>Text: # Business Impact: FraudDetection\n\n## Executive Summary\nThe FraudDetection system has delivered exce...",
          "Type: business<br>Text: # Business Impact: HealthTrack\n\n## Executive Summary\nHealthTrack has established itself as a leading...",
          "Type: business<br>Text: # Business Impact: MicroServices Migration\n\n## Executive Summary\nThe MicroServices Migration initiat...",
          "Type: developers<br>Text: # Developer Profile: Alex Chen\n\n## Personal Information\n- **Name**: Alex Chen\n- **Position**: Data S...",
          "Type: developers<br>Text: # Developer Profile: John Smith\n\n## Personal Information\n- **Name**: John Smith\n- **Position**: Seni...",
          "Type: developers<br>Text: # Developer Profile: Raj Patel\n\n## Personal Information\n- **Name**: Raj Patel\n- **Position**: DevOps...",
          "Type: developers<br>Text: # Developer Profile: Sarah Johnson\n\n## Personal Information\n- **Name**: Sarah Johnson\n- **Position**...",
          "Type: projects<br>Text: # Project: CloudSync\n\n## Overview\nCloudSync is a cloud-based file synchronization and sharing platfo...",
          "Type: projects<br>Text: # Project: DataViz\n\n## Overview\nDataViz is an enterprise data visualization and analytics platform t...",
          "Type: projects<br>Text: # Project: FraudDetection\n\n## Overview\nFraudDetection is an AI-powered system that identifies and pr...",
          "Type: projects<br>Text: # Project: HealthTrack\n\n## Overview\nHealthTrack is a mobile and web application for personal health ...",
          "Type: projects<br>Text: # Project: MicroServices Migration\n\n## Overview\nA strategic initiative to decompose the company's mo..."
         ],
         "type": "scatter",
         "x": {
          "bdata": "icAJQpkQaMFM4gnCkBhgwgwiUkEQyfHBTLMLQeRtBkFqkTBCr8JDQjcUg8CgxJDC5CFbwvpIS0I=",
          "dtype": "f4"
         },
         "y": {
          "bdata": "9kKuQYBNrkGEIH5CayafQDnAh0Iw5L/CqAyZwtim8cKeU63CjiNswbyVj8FVz2RCJjoIwnL3i0I=",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "height": 600,
        "margin": {
         "b": 10,
         "l": 10,
         "r": 20,
         "t": 40
        },
        "scene": {
         "xaxis": {
          "title": {
           "text": "x"
          }
         },
         "yaxis": {
          "title": {
           "text": "y"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "2D Chroma Vector Store Visualization"
        },
        "width": 800
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42, perplexity=10)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[go.Scatter(\n",
    "        x=reduced_vectors[:, 0],\n",
    "        y=reduced_vectors[:, 1],\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, color=colors),\n",
    "        text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "        hoverinfo='text'\n",
    "    )]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b934b5",
   "metadata": {},
   "source": [
    "### Putting together: RAG using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bbb43384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeekerG\\AppData\\Local\\Temp\\ipykernel_14332\\167896186.py:4: LangChainDeprecationWarning:\n",
      "\n",
      "Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. LLM: We already declared the LLM above\n",
    "\n",
    "# 2. memory: This tracks the conversation history\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# 3. Retriever: This retrieves the context related documents from the vector store\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 4. Chain: This combines the LLM, memory and retriever into a single chain\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(llm=llm, memory=memory, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "995a0dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What's the best project in terms of revenue?\n",
      "Answer: The project with the best revenue is DataViz, which has an annual recurring revenue of $7.2 million.\n"
     ]
    }
   ],
   "source": [
    "query = \"What's the best project in terms of revenue?\"\n",
    "result = rag_chain.invoke({\"question\": query})\n",
    "print('Question:', query)\n",
    "print('Answer:', result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a827febd",
   "metadata": {},
   "source": [
    "### Gradio with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1fdf0ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "# Business Impact: DataViz\n",
      "\n",
      "## Executive Summary\n",
      "DataViz has revolutionized how our enterprise clients derive insights from their data, resulting in measurable business value through improved decision-making, operational efficiency, and strategic planning capabilities.\n",
      "\n",
      "## Key Performance Indicators\n",
      "- **Client Acquisition**: 42 enterprise clients in first year\n",
      "- **Revenue**: $7.2M annual recurring revenue\n",
      "- **Contract Renewal Rate**: 94%\n",
      "- **Expansion Revenue**: 40% increase from existing clients\n",
      "\n",
      "## Business Value\n",
      "- **Decision Latency**: Reduced from weeks to hours\n",
      "- **Data Utilization**: Increased by 145%\n",
      "- **Operational Efficiency**: 28% improvement reported by clients\n",
      "- **Self-service Analytics**: 82% of queries now handled without IT involvement\n",
      "\n",
      "## Client Testimonials\n",
      "> \"DataViz transformed our business intelligence capabilities. What previously took a team of analysts weeks can now be visualized in real-time by decision-makers.\" - CIO, Fortune 500 Retail Company\n",
      "\n",
      "> \"The customizable dashboards have become central to our daily operations. We've identified cost-saving opportunities we never would have discovered otherwise.\" - VP Analytics, Financial Services Firm\n",
      "\n",
      "## Future Business Opportunities\n",
      "- Expansion into predictive analytics offerings\n",
      "- Industry-specific dashboard templates and solutions\n",
      "- Consulting services around data strategy\n",
      "- Integration with enterprise planning systems\n",
      "\n",
      "## Recommendations\n",
      "- Accelerate ML-powered forecasting features to capture premium market segment\n",
      "- Develop industry-specific solutions for healthcare and financial services\n",
      "- Establish strategic partnerships with complementary enterprise software providers\n",
      "\n",
      "# Business Impact: FraudDetection\n",
      "\n",
      "## Executive Summary\n",
      "The FraudDetection system has delivered exceptional business value by significantly reducing financial losses from fraudulent activities while improving customer experience through reduced false positives and faster transaction processing.\n",
      "\n",
      "## Key Performance Indicators\n",
      "- **Fraud Prevention**: $2.8M annual direct savings\n",
      "- **False Positive Reduction**: 68% decrease in legitimate transactions flagged\n",
      "- **Customer Satisfaction**: 22% increase in satisfaction scores\n",
      "- **Transaction Approval Time**: Reduced by 84%\n",
      "\n",
      "## Business Value\n",
      "- **Financial Protection**: Prevented an estimated $5.2M in potential fraud losses\n",
      "- **Reputation Enhancement**: Public recognition as industry security leader\n",
      "- **Regulatory Compliance**: Exceeds all regulatory requirements for fraud monitoring\n",
      "- **Operational Efficiency**: 76% reduction in manual review requirements\n",
      "\n",
      "## Stakeholder Testimonials\n",
      "> \"The return on investment from our FraudDetection implementation has far exceeded our projections. Beyond the direct cost savings, the improvement in customer experience has been remarkable.\" - CFO\n",
      "\n",
      "> \"As the head of risk management, I've been particularly impressed by the system's adaptability to new fraud patterns. The machine learning models have proven extraordinarily effective.\" - Chief Risk Officer\n",
      "\n",
      "## Future Business Opportunities\n",
      "- Licensing the technology to partner financial institutions\n",
      "- Expanding into adjacent security domains (AML, KYC verification)\n",
      "- Developing industry-specific fraud detection solutions\n",
      "- Offering fraud analytics as a consulting service\n",
      "\n",
      "## Recommendations\n",
      "- Accelerate advanced anomaly detection features\n",
      "- Develop APIs for third-party integration\n",
      "- Create industry benchmark reports to strengthen thought leadership position\n",
      "- Explore strategic partnerships with complementary fintech providers\n",
      "\n",
      "# Project: DataViz\n",
      "\n",
      "## Overview\n",
      "DataViz is an enterprise data visualization and analytics platform that transforms complex datasets into interactive, insightful dashboards. It supports real-time data processing and offers customizable visualization components for business intelligence.\n",
      "\n",
      "## Technical Details\n",
      "- **Stack**: Vue.js, D3.js, FastAPI, Elasticsearch\n",
      "- **Cloud Provider**: GCP\n",
      "- **Architecture**: Event-driven\n",
      "- **APIs**: REST, WebSockets\n",
      "- **Authentication**: OAuth 2.0, API Keys\n",
      "\n",
      "## Team\n",
      "- **Project Lead**: Lisa Wong\n",
      "- **Frontend Developers**: Sarah Johnson, Tyler Adams\n",
      "- **Backend Developers**: John Smith, Eric Johnson\n",
      "- **Data Engineers**: Alex Chen, Michael Brown\n",
      "- **QA**: David Kim\n",
      "\n",
      "## Timeline\n",
      "- **Started**: September 2021\n",
      "- **Beta Launch**: May 2022\n",
      "- **Production Release**: August 2022\n",
      "- **Current Version**: 3.1.2\n",
      "- **Next Milestone**: Advanced ML-powered forecasting (Q2 2023)\n",
      "\n",
      "## Key Metrics\n",
      "- **Code Coverage**: 89%\n",
      "- **Enterprise Clients**: 42\n",
      "- **Dashboards Created**: 3,800+\n",
      "- **Avg. Dashboard Load Time**: 1.2s\n",
      "- **Data Processed Daily**: 8TB\n",
      "\n",
      "## Challenges\n",
      "- Maintaining performance with large datasets\n",
      "- Creating intuitive UX for complex data operations\n",
      "- Implementing real-time collaboration features\n",
      "\n",
      "# Business Impact: HealthTrack\n",
      "\n",
      "## Executive Summary\n",
      "HealthTrack has established itself as a leading health monitoring platform in the consumer market, driving significant revenue growth and expanding our user base into previously untapped demographics.\n",
      "\n",
      "## Key Performance Indicators\n",
      "- **User Growth**: 215% year-over-year\n",
      "- **Revenue**: $4.8M in first year\n",
      "- **Retention Rate**: 78% (industry average: 43%)\n",
      "- **Subscription Conversion**: 32% of free-tier users\n",
      "\n",
      "## Business Value\n",
      "- **Market Penetration**: Captured 14% of health tracking app market\n",
      "- **Brand Enhancement**: Partner inquiries increased by 180%\n",
      "- **Customer Acquisition Cost**: Reduced from $38 to $22\n",
      "- **Lifetime Value**: Average $185 per user\n",
      "\n",
      "## User Testimonials\n",
      "> \"HealthTrack has completely changed how I approach my fitness goals. The insights are actionable and the interface is intuitive.\" - App Store Review\n",
      "\n",
      "> \"As someone with chronic health conditions, HealthTrack helps me monitor vital metrics and share them with my healthcare provider. It's been invaluable.\" - User Survey\n",
      "\n",
      "## Future Business Opportunities\n",
      "- Healthcare provider partnerships for patient monitoring\n",
      "- Insurance company wellness program integration\n",
      "- Corporate wellness program white-label solutions\n",
      "- Premium tier with advanced health analytics\n",
      "\n",
      "## Recommendations\n",
      "- Prioritize AI-powered health insights to increase premium tier conversions\n",
      "- Develop HIPAA-compliant data sharing for healthcare integration\n",
      "- Expand wearable device integration to capture additional market segments\n",
      "Human: suggest 1 project with the highest scope for revenue?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: suggest 1 project with the highest scope for revenue?\n",
      "Assistant: The \"FraudDetection\" project presents the highest scope for revenue. It not only delivers significant direct savings from fraud prevention ($2.8M annual direct savings) but also has the potential to expand into adjacent security domains, develop industry-specific solutions, and offer fraud analytics as a consulting service. Additionally, licensing the technology to partner financial institutions could create substantial revenue opportunities.\n",
      "Follow Up Input: how much will it generate?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "# Business Impact: FraudDetection\n",
      "\n",
      "## Executive Summary\n",
      "The FraudDetection system has delivered exceptional business value by significantly reducing financial losses from fraudulent activities while improving customer experience through reduced false positives and faster transaction processing.\n",
      "\n",
      "## Key Performance Indicators\n",
      "- **Fraud Prevention**: $2.8M annual direct savings\n",
      "- **False Positive Reduction**: 68% decrease in legitimate transactions flagged\n",
      "- **Customer Satisfaction**: 22% increase in satisfaction scores\n",
      "- **Transaction Approval Time**: Reduced by 84%\n",
      "\n",
      "## Business Value\n",
      "- **Financial Protection**: Prevented an estimated $5.2M in potential fraud losses\n",
      "- **Reputation Enhancement**: Public recognition as industry security leader\n",
      "- **Regulatory Compliance**: Exceeds all regulatory requirements for fraud monitoring\n",
      "- **Operational Efficiency**: 76% reduction in manual review requirements\n",
      "\n",
      "## Stakeholder Testimonials\n",
      "> \"The return on investment from our FraudDetection implementation has far exceeded our projections. Beyond the direct cost savings, the improvement in customer experience has been remarkable.\" - CFO\n",
      "\n",
      "> \"As the head of risk management, I've been particularly impressed by the system's adaptability to new fraud patterns. The machine learning models have proven extraordinarily effective.\" - Chief Risk Officer\n",
      "\n",
      "## Future Business Opportunities\n",
      "- Licensing the technology to partner financial institutions\n",
      "- Expanding into adjacent security domains (AML, KYC verification)\n",
      "- Developing industry-specific fraud detection solutions\n",
      "- Offering fraud analytics as a consulting service\n",
      "\n",
      "## Recommendations\n",
      "- Accelerate advanced anomaly detection features\n",
      "- Develop APIs for third-party integration\n",
      "- Create industry benchmark reports to strengthen thought leadership position\n",
      "- Explore strategic partnerships with complementary fintech providers\n",
      "\n",
      "# Project: FraudDetection\n",
      "\n",
      "## Overview\n",
      "FraudDetection is an AI-powered system that identifies and prevents fraudulent transactions in real-time. The platform uses machine learning models to analyze transaction patterns and detect anomalies across multiple financial channels.\n",
      "\n",
      "## Technical Details\n",
      "- **Stack**: Python, TensorFlow, Spark, Kafka, PostgreSQL\n",
      "- **Cloud Provider**: AWS\n",
      "- **Architecture**: Lambda architecture (batch + stream processing)\n",
      "- **APIs**: REST, Apache Avro\n",
      "- **ML Models**: XGBoost, Neural Networks\n",
      "\n",
      "## Team\n",
      "- **Project Lead**: Michael Brown\n",
      "- **ML Engineers**: Alex Chen, Tanya Sharma\n",
      "- **Data Engineers**: Lisa Wong, Eric Johnson\n",
      "- **DevOps**: Raj Patel\n",
      "- **Security Specialists**: David Kim, Maria Rodriguez\n",
      "\n",
      "## Timeline\n",
      "- **Started**: July 2021\n",
      "- **Pilot Launch**: March 2022\n",
      "- **Production Release**: June 2022\n",
      "- **Current Version**: 2.4.1\n",
      "- **Next Milestone**: Advanced anomaly detection (Q3 2023)\n",
      "\n",
      "## Key Metrics\n",
      "- **Fraud Detection Rate**: 96.3%\n",
      "- **False Positive Rate**: 2.1%\n",
      "- **Avg. Detection Time**: 285ms\n",
      "- **Daily Transactions Processed**: 4.5 million\n",
      "- **Cost Savings**: $2.8M annual fraud prevention\n",
      "\n",
      "## Challenges\n",
      "- Balancing false positives with detection sensitivity\n",
      "- Processing high-volume transactions in real-time\n",
      "- Adapting to evolving fraud techniques\n",
      "\n",
      "# Business Impact: DataViz\n",
      "\n",
      "## Executive Summary\n",
      "DataViz has revolutionized how our enterprise clients derive insights from their data, resulting in measurable business value through improved decision-making, operational efficiency, and strategic planning capabilities.\n",
      "\n",
      "## Key Performance Indicators\n",
      "- **Client Acquisition**: 42 enterprise clients in first year\n",
      "- **Revenue**: $7.2M annual recurring revenue\n",
      "- **Contract Renewal Rate**: 94%\n",
      "- **Expansion Revenue**: 40% increase from existing clients\n",
      "\n",
      "## Business Value\n",
      "- **Decision Latency**: Reduced from weeks to hours\n",
      "- **Data Utilization**: Increased by 145%\n",
      "- **Operational Efficiency**: 28% improvement reported by clients\n",
      "- **Self-service Analytics**: 82% of queries now handled without IT involvement\n",
      "\n",
      "## Client Testimonials\n",
      "> \"DataViz transformed our business intelligence capabilities. What previously took a team of analysts weeks can now be visualized in real-time by decision-makers.\" - CIO, Fortune 500 Retail Company\n",
      "\n",
      "> \"The customizable dashboards have become central to our daily operations. We've identified cost-saving opportunities we never would have discovered otherwise.\" - VP Analytics, Financial Services Firm\n",
      "\n",
      "## Future Business Opportunities\n",
      "- Expansion into predictive analytics offerings\n",
      "- Industry-specific dashboard templates and solutions\n",
      "- Consulting services around data strategy\n",
      "- Integration with enterprise planning systems\n",
      "\n",
      "## Recommendations\n",
      "- Accelerate ML-powered forecasting features to capture premium market segment\n",
      "- Develop industry-specific solutions for healthcare and financial services\n",
      "- Establish strategic partnerships with complementary enterprise software providers\n",
      "\n",
      "# Business Impact: HealthTrack\n",
      "\n",
      "## Executive Summary\n",
      "HealthTrack has established itself as a leading health monitoring platform in the consumer market, driving significant revenue growth and expanding our user base into previously untapped demographics.\n",
      "\n",
      "## Key Performance Indicators\n",
      "- **User Growth**: 215% year-over-year\n",
      "- **Revenue**: $4.8M in first year\n",
      "- **Retention Rate**: 78% (industry average: 43%)\n",
      "- **Subscription Conversion**: 32% of free-tier users\n",
      "\n",
      "## Business Value\n",
      "- **Market Penetration**: Captured 14% of health tracking app market\n",
      "- **Brand Enhancement**: Partner inquiries increased by 180%\n",
      "- **Customer Acquisition Cost**: Reduced from $38 to $22\n",
      "- **Lifetime Value**: Average $185 per user\n",
      "\n",
      "## User Testimonials\n",
      "> \"HealthTrack has completely changed how I approach my fitness goals. The insights are actionable and the interface is intuitive.\" - App Store Review\n",
      "\n",
      "> \"As someone with chronic health conditions, HealthTrack helps me monitor vital metrics and share them with my healthcare provider. It's been invaluable.\" - User Survey\n",
      "\n",
      "## Future Business Opportunities\n",
      "- Healthcare provider partnerships for patient monitoring\n",
      "- Insurance company wellness program integration\n",
      "- Corporate wellness program white-label solutions\n",
      "- Premium tier with advanced health analytics\n",
      "\n",
      "## Recommendations\n",
      "- Prioritize AI-powered health insights to increase premium tier conversions\n",
      "- Develop HIPAA-compliant data sharing for healthcare integration\n",
      "- Expand wearable device integration to capture additional market segments\n",
      "Human: How much revenue will the \"FraudDetection\" project generate?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: suggest 1 project with the highest scope for revenue?\n",
      "Assistant: The \"FraudDetection\" project presents the highest scope for revenue. It not only delivers significant direct savings from fraud prevention ($2.8M annual direct savings) but also has the potential to expand into adjacent security domains, develop industry-specific solutions, and offer fraud analytics as a consulting service. Additionally, licensing the technology to partner financial institutions could create substantial revenue opportunities.\n",
      "Human: how much will it generate?\n",
      "Assistant: The provided context does not specify the revenue generated by the FraudDetection project. Therefore, I don't know the answer.\n",
      "Follow Up Input: who is the best person to lead?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "# Project: FraudDetection\n",
      "\n",
      "## Overview\n",
      "FraudDetection is an AI-powered system that identifies and prevents fraudulent transactions in real-time. The platform uses machine learning models to analyze transaction patterns and detect anomalies across multiple financial channels.\n",
      "\n",
      "## Technical Details\n",
      "- **Stack**: Python, TensorFlow, Spark, Kafka, PostgreSQL\n",
      "- **Cloud Provider**: AWS\n",
      "- **Architecture**: Lambda architecture (batch + stream processing)\n",
      "- **APIs**: REST, Apache Avro\n",
      "- **ML Models**: XGBoost, Neural Networks\n",
      "\n",
      "## Team\n",
      "- **Project Lead**: Michael Brown\n",
      "- **ML Engineers**: Alex Chen, Tanya Sharma\n",
      "- **Data Engineers**: Lisa Wong, Eric Johnson\n",
      "- **DevOps**: Raj Patel\n",
      "- **Security Specialists**: David Kim, Maria Rodriguez\n",
      "\n",
      "## Timeline\n",
      "- **Started**: July 2021\n",
      "- **Pilot Launch**: March 2022\n",
      "- **Production Release**: June 2022\n",
      "- **Current Version**: 2.4.1\n",
      "- **Next Milestone**: Advanced anomaly detection (Q3 2023)\n",
      "\n",
      "## Key Metrics\n",
      "- **Fraud Detection Rate**: 96.3%\n",
      "- **False Positive Rate**: 2.1%\n",
      "- **Avg. Detection Time**: 285ms\n",
      "- **Daily Transactions Processed**: 4.5 million\n",
      "- **Cost Savings**: $2.8M annual fraud prevention\n",
      "\n",
      "## Challenges\n",
      "- Balancing false positives with detection sensitivity\n",
      "- Processing high-volume transactions in real-time\n",
      "- Adapting to evolving fraud techniques\n",
      "\n",
      "# Business Impact: FraudDetection\n",
      "\n",
      "## Executive Summary\n",
      "The FraudDetection system has delivered exceptional business value by significantly reducing financial losses from fraudulent activities while improving customer experience through reduced false positives and faster transaction processing.\n",
      "\n",
      "## Key Performance Indicators\n",
      "- **Fraud Prevention**: $2.8M annual direct savings\n",
      "- **False Positive Reduction**: 68% decrease in legitimate transactions flagged\n",
      "- **Customer Satisfaction**: 22% increase in satisfaction scores\n",
      "- **Transaction Approval Time**: Reduced by 84%\n",
      "\n",
      "## Business Value\n",
      "- **Financial Protection**: Prevented an estimated $5.2M in potential fraud losses\n",
      "- **Reputation Enhancement**: Public recognition as industry security leader\n",
      "- **Regulatory Compliance**: Exceeds all regulatory requirements for fraud monitoring\n",
      "- **Operational Efficiency**: 76% reduction in manual review requirements\n",
      "\n",
      "## Stakeholder Testimonials\n",
      "> \"The return on investment from our FraudDetection implementation has far exceeded our projections. Beyond the direct cost savings, the improvement in customer experience has been remarkable.\" - CFO\n",
      "\n",
      "> \"As the head of risk management, I've been particularly impressed by the system's adaptability to new fraud patterns. The machine learning models have proven extraordinarily effective.\" - Chief Risk Officer\n",
      "\n",
      "## Future Business Opportunities\n",
      "- Licensing the technology to partner financial institutions\n",
      "- Expanding into adjacent security domains (AML, KYC verification)\n",
      "- Developing industry-specific fraud detection solutions\n",
      "- Offering fraud analytics as a consulting service\n",
      "\n",
      "## Recommendations\n",
      "- Accelerate advanced anomaly detection features\n",
      "- Develop APIs for third-party integration\n",
      "- Create industry benchmark reports to strengthen thought leadership position\n",
      "- Explore strategic partnerships with complementary fintech providers\n",
      "\n",
      "# Developer Profile: Alex Chen\n",
      "\n",
      "## Personal Information\n",
      "- **Name**: Alex Chen\n",
      "- **Position**: Data Scientist / ML Engineer\n",
      "- **Email**: alex.chen@example.com\n",
      "- **Location**: Boston, MA\n",
      "- **Years of Experience**: 7\n",
      "\n",
      "## Skills\n",
      "- **Programming Languages**: Python, R, SQL, Julia\n",
      "- **Frameworks/Libraries**: TensorFlow, PyTorch, scikit-learn, Pandas\n",
      "- **Cloud Platforms**: AWS SageMaker, Azure ML, GCP Vertex AI\n",
      "- **Other Tools**: Jupyter, MLflow, DVC, Docker\n",
      "\n",
      "## Projects\n",
      "- Lead data scientist for CustomerInsights predictive analytics\n",
      "- ML architect for FraudDetection system\n",
      "- Research contributor to NLP recommendation engine\n",
      "\n",
      "## Education\n",
      "- Ph.D. Machine Learning, MIT, 2019\n",
      "- M.S. Applied Mathematics, Stanford University, 2015\n",
      "- B.S. Computer Science, UC Berkeley, 2013\n",
      "\n",
      "## Certifications\n",
      "- TensorFlow Developer Certification\n",
      "- AWS Certified Machine Learning - Specialty\n",
      "- Microsoft Certified: Azure AI Engineer Associate\n",
      "\n",
      "## Performance Metrics\n",
      "- **Model Accuracy**: 94.3%\n",
      "- **Production Deployment Rate**: 85%\n",
      "- **Research Publications**: 5\n",
      "- **Peer Review Rating**: 4.9/5\n",
      "\n",
      "# Project: DataViz\n",
      "\n",
      "## Overview\n",
      "DataViz is an enterprise data visualization and analytics platform that transforms complex datasets into interactive, insightful dashboards. It supports real-time data processing and offers customizable visualization components for business intelligence.\n",
      "\n",
      "## Technical Details\n",
      "- **Stack**: Vue.js, D3.js, FastAPI, Elasticsearch\n",
      "- **Cloud Provider**: GCP\n",
      "- **Architecture**: Event-driven\n",
      "- **APIs**: REST, WebSockets\n",
      "- **Authentication**: OAuth 2.0, API Keys\n",
      "\n",
      "## Team\n",
      "- **Project Lead**: Lisa Wong\n",
      "- **Frontend Developers**: Sarah Johnson, Tyler Adams\n",
      "- **Backend Developers**: John Smith, Eric Johnson\n",
      "- **Data Engineers**: Alex Chen, Michael Brown\n",
      "- **QA**: David Kim\n",
      "\n",
      "## Timeline\n",
      "- **Started**: September 2021\n",
      "- **Beta Launch**: May 2022\n",
      "- **Production Release**: August 2022\n",
      "- **Current Version**: 3.1.2\n",
      "- **Next Milestone**: Advanced ML-powered forecasting (Q2 2023)\n",
      "\n",
      "## Key Metrics\n",
      "- **Code Coverage**: 89%\n",
      "- **Enterprise Clients**: 42\n",
      "- **Dashboards Created**: 3,800+\n",
      "- **Avg. Dashboard Load Time**: 1.2s\n",
      "- **Data Processed Daily**: 8TB\n",
      "\n",
      "## Challenges\n",
      "- Maintaining performance with large datasets\n",
      "- Creating intuitive UX for complex data operations\n",
      "- Implementing real-time collaboration features\n",
      "Human: Who is the best person to lead the FraudDetection project?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# reset the memory and use that for the gradio chat\n",
    "chat_memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "chat_rag_chain = ConversationalRetrievalChain.from_llm(llm=llm, memory=chat_memory, retriever=retriever, callbacks=[StdOutCallbackHandler()])\n",
    "\n",
    "\n",
    "def chat(message, history):\n",
    "    # we dont need to manually add the msg to history since langchain RAG\n",
    "    # does that using the memory object\n",
    "    result = chat_rag_chain.invoke({\"question\": message})\n",
    "    return result['answer']\n",
    "\n",
    "import gradio as gr\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5bae59",
   "metadata": {},
   "source": [
    "### RAG: Open source LLMs and Embeddings\n",
    "\n",
    "Instead of relying on paid LLMs for RAG, we can instead use the open source LLMs and word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca99efe7",
   "metadata": {},
   "source": [
    "#### Ollama + FAISS (vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7932f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3cc65502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS db path:  notebooks\\vector_store\\faiss_rag_db\\faiss.pkl\n",
      "FAISS db file not found, creating a new one\n",
      "FAISS vectorstore created in memory\n",
      "FAISS vectorstore saved to path: notebooks\\vector_store\\faiss_rag_db\\faiss.pkl\n"
     ]
    }
   ],
   "source": [
    "# We will use an open source embedding called \"nomic-embed-text\", you can find it from ollama models hub.\n",
    "ollama_embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "faiss_db_path = os.path.join(\"notebooks\", \"vector_store\", \"faiss_rag_db\", \"faiss.pkl\")\n",
    "print(\"FAISS db path: \", faiss_db_path)\n",
    "\n",
    "faiss_vectorstore = None\n",
    "\n",
    "# check if the faiss data file exists\n",
    "if os.path.exists(faiss_db_path):\n",
    "    # load from the file\n",
    "    faiss_vectorstore = FAISS.load_local(faiss_db_path, ollama_embedding, allow_dangerous_deserialization=True)\n",
    "    print('FAISS db file found, loaded from the file')\n",
    "else:\n",
    "    print('FAISS db file not found, creating a new one')\n",
    "    os.makedirs(faiss_db_path, exist_ok=True)\n",
    "    faiss_vectorstore = FAISS.from_documents(documents=chunks, embedding=ollama_embedding)\n",
    "    print(f\"FAISS vectorstore created in memory\")\n",
    "    \n",
    "    faiss_vectorstore.save_local(faiss_db_path)\n",
    "    print(f\"FAISS vectorstore saved to path: {faiss_db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db680672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "{'3113b1fd-24cc-438b-ace5-2943b767915d': Document(id='3113b1fd-24cc-438b-ace5-2943b767915d', metadata={'source': 'data\\\\business\\\\cloudsync_impact.md', 'doc_type': 'business'}, page_content='# Business Impact: CloudSync\\n\\n## Executive Summary\\nCloudSync has transformed internal collaboration workflows and enhanced security posture, resulting in significant productivity gains and cost reductions across all business units.\\n\\n## Key Performance Indicators\\n- **ROI**: 287% over 18 months\\n- **Annual Cost Savings**: $1.2M\\n- **Productivity Increase**: 23%\\n- **Security Incidents**: Reduced by 62%\\n\\n## Business Value\\n- **Collaboration Enhancement**: Cross-team document sharing increased by 78%\\n- **Process Acceleration**: Approval workflows reduced from 5 days to 6 hours\\n- **Compliance Adherence**: 100% compliance with industry regulations\\n- **Risk Mitigation**: Data loss risk reduced by estimated 85%\\n\\n## Customer Testimonials\\n> \"CloudSync has fundamentally changed how our teams collaborate. The security features give us confidence while the intuitive interface keeps adoption high.\" - VP of Operations\\n\\n> \"The ROI was evident within the first quarter. We\\'ve seen dramatic improvements in workflow efficiency.\" - CIO\\n\\n## Future Business Opportunities\\n- Expansion to partner organization access\\n- Integration with industry-specific compliance frameworks\\n- Enhanced analytics suite for collaboration insights\\n\\n## Recommendations\\n- Accelerate multi-region deployment to support global teams\\n- Invest in advanced permission management features\\n- Develop tiered storage options for cost optimization'), '67951f8c-a960-4ef1-b8ad-64d66f65396b': Document(id='67951f8c-a960-4ef1-b8ad-64d66f65396b', metadata={'source': 'data\\\\business\\\\dataviz_impact.md', 'doc_type': 'business'}, page_content='# Business Impact: DataViz\\n\\n## Executive Summary\\nDataViz has revolutionized how our enterprise clients derive insights from their data, resulting in measurable business value through improved decision-making, operational efficiency, and strategic planning capabilities.\\n\\n## Key Performance Indicators\\n- **Client Acquisition**: 42 enterprise clients in first year\\n- **Revenue**: $7.2M annual recurring revenue\\n- **Contract Renewal Rate**: 94%\\n- **Expansion Revenue**: 40% increase from existing clients\\n\\n## Business Value\\n- **Decision Latency**: Reduced from weeks to hours\\n- **Data Utilization**: Increased by 145%\\n- **Operational Efficiency**: 28% improvement reported by clients\\n- **Self-service Analytics**: 82% of queries now handled without IT involvement\\n\\n## Client Testimonials\\n> \"DataViz transformed our business intelligence capabilities. What previously took a team of analysts weeks can now be visualized in real-time by decision-makers.\" - CIO, Fortune 500 Retail Company\\n\\n> \"The customizable dashboards have become central to our daily operations. We\\'ve identified cost-saving opportunities we never would have discovered otherwise.\" - VP Analytics, Financial Services Firm\\n\\n## Future Business Opportunities\\n- Expansion into predictive analytics offerings\\n- Industry-specific dashboard templates and solutions\\n- Consulting services around data strategy\\n- Integration with enterprise planning systems\\n\\n## Recommendations\\n- Accelerate ML-powered forecasting features to capture premium market segment\\n- Develop industry-specific solutions for healthcare and financial services\\n- Establish strategic partnerships with complementary enterprise software providers'), 'e8d75611-2a13-40ad-8254-64a4e833aebd': Document(id='e8d75611-2a13-40ad-8254-64a4e833aebd', metadata={'source': 'data\\\\business\\\\fraud_detection_impact.md', 'doc_type': 'business'}, page_content='# Business Impact: FraudDetection\\n\\n## Executive Summary\\nThe FraudDetection system has delivered exceptional business value by significantly reducing financial losses from fraudulent activities while improving customer experience through reduced false positives and faster transaction processing.\\n\\n## Key Performance Indicators\\n- **Fraud Prevention**: $2.8M annual direct savings\\n- **False Positive Reduction**: 68% decrease in legitimate transactions flagged\\n- **Customer Satisfaction**: 22% increase in satisfaction scores\\n- **Transaction Approval Time**: Reduced by 84%\\n\\n## Business Value\\n- **Financial Protection**: Prevented an estimated $5.2M in potential fraud losses\\n- **Reputation Enhancement**: Public recognition as industry security leader\\n- **Regulatory Compliance**: Exceeds all regulatory requirements for fraud monitoring\\n- **Operational Efficiency**: 76% reduction in manual review requirements\\n\\n## Stakeholder Testimonials\\n> \"The return on investment from our FraudDetection implementation has far exceeded our projections. Beyond the direct cost savings, the improvement in customer experience has been remarkable.\" - CFO\\n\\n> \"As the head of risk management, I\\'ve been particularly impressed by the system\\'s adaptability to new fraud patterns. The machine learning models have proven extraordinarily effective.\" - Chief Risk Officer\\n\\n## Future Business Opportunities\\n- Licensing the technology to partner financial institutions\\n- Expanding into adjacent security domains (AML, KYC verification)\\n- Developing industry-specific fraud detection solutions\\n- Offering fraud analytics as a consulting service\\n\\n## Recommendations\\n- Accelerate advanced anomaly detection features\\n- Develop APIs for third-party integration\\n- Create industry benchmark reports to strengthen thought leadership position\\n- Explore strategic partnerships with complementary fintech providers'), 'a235f8a4-4938-4039-bf73-e7f5c6065f70': Document(id='a235f8a4-4938-4039-bf73-e7f5c6065f70', metadata={'source': 'data\\\\business\\\\healthtrack_impact.md', 'doc_type': 'business'}, page_content='# Business Impact: HealthTrack\\n\\n## Executive Summary\\nHealthTrack has established itself as a leading health monitoring platform in the consumer market, driving significant revenue growth and expanding our user base into previously untapped demographics.\\n\\n## Key Performance Indicators\\n- **User Growth**: 215% year-over-year\\n- **Revenue**: $4.8M in first year\\n- **Retention Rate**: 78% (industry average: 43%)\\n- **Subscription Conversion**: 32% of free-tier users\\n\\n## Business Value\\n- **Market Penetration**: Captured 14% of health tracking app market\\n- **Brand Enhancement**: Partner inquiries increased by 180%\\n- **Customer Acquisition Cost**: Reduced from $38 to $22\\n- **Lifetime Value**: Average $185 per user\\n\\n## User Testimonials\\n> \"HealthTrack has completely changed how I approach my fitness goals. The insights are actionable and the interface is intuitive.\" - App Store Review\\n\\n> \"As someone with chronic health conditions, HealthTrack helps me monitor vital metrics and share them with my healthcare provider. It\\'s been invaluable.\" - User Survey\\n\\n## Future Business Opportunities\\n- Healthcare provider partnerships for patient monitoring\\n- Insurance company wellness program integration\\n- Corporate wellness program white-label solutions\\n- Premium tier with advanced health analytics\\n\\n## Recommendations\\n- Prioritize AI-powered health insights to increase premium tier conversions\\n- Develop HIPAA-compliant data sharing for healthcare integration\\n- Expand wearable device integration to capture additional market segments'), 'b1756d18-3ddd-40fa-8a71-924972555565': Document(id='b1756d18-3ddd-40fa-8a71-924972555565', metadata={'source': 'data\\\\business\\\\microservices_impact.md', 'doc_type': 'business'}, page_content='# Business Impact: MicroServices Migration\\n\\n## Executive Summary\\nThe MicroServices Migration initiative has transformed our legacy technology infrastructure, significantly enhancing our ability to respond to market demands while reducing operational costs and technical debt.\\n\\n## Key Performance Indicators\\n- **Development Velocity**: Increased by 385%\\n- **Time-to-Market**: Reduced from 6 months to 3 weeks for new features\\n- **System Availability**: Improved from 99.5% to 99.98%\\n- **Cost Efficiency**: 32% infrastructure cost reduction\\n\\n## Business Value\\n- **Business Agility**: Ability to pivot product direction with minimal technical constraints\\n- **Operational Excellence**: Reduced maintenance burden by 58%\\n- **Innovation Acceleration**: New feature delivery rate increased by 275%\\n- **Talent Acquisition**: 40% improvement in engineering recruitment success rate\\n\\n## Management Testimonials\\n> \"The microservices architecture has been transformative for our business strategy. We can now respond to market opportunities in weeks instead of quarters.\" - CEO\\n\\n> \"What impressed me most was the seamless transition. Our customers experienced improved performance without disruption to their workflows.\" - COO\\n\\n## Future Business Opportunities\\n- Platform-as-a-Service offerings leveraging our microservices architecture\\n- More granular product offerings based on individual service capabilities\\n- Accelerated integration with third-party solutions\\n- Improved experimentation capacity for new business models\\n\\n## Recommendations\\n- Complete final phase of migration ahead of schedule to realize full benefits\\n- Implement comprehensive service catalog for business stakeholders\\n- Develop internal training program for product managers on microservices capabilities'), '6bbc49a2-0f6f-4f82-b8e7-f4357a894abe': Document(id='6bbc49a2-0f6f-4f82-b8e7-f4357a894abe', metadata={'source': 'data\\\\developers\\\\alex_chen.md', 'doc_type': 'developers'}, page_content='# Developer Profile: Alex Chen\\n\\n## Personal Information\\n- **Name**: Alex Chen\\n- **Position**: Data Scientist / ML Engineer\\n- **Email**: alex.chen@example.com\\n- **Location**: Boston, MA\\n- **Years of Experience**: 7\\n\\n## Skills\\n- **Programming Languages**: Python, R, SQL, Julia\\n- **Frameworks/Libraries**: TensorFlow, PyTorch, scikit-learn, Pandas\\n- **Cloud Platforms**: AWS SageMaker, Azure ML, GCP Vertex AI\\n- **Other Tools**: Jupyter, MLflow, DVC, Docker\\n\\n## Projects\\n- Lead data scientist for CustomerInsights predictive analytics\\n- ML architect for FraudDetection system\\n- Research contributor to NLP recommendation engine\\n\\n## Education\\n- Ph.D. Machine Learning, MIT, 2019\\n- M.S. Applied Mathematics, Stanford University, 2015\\n- B.S. Computer Science, UC Berkeley, 2013\\n\\n## Certifications\\n- TensorFlow Developer Certification\\n- AWS Certified Machine Learning - Specialty\\n- Microsoft Certified: Azure AI Engineer Associate\\n\\n## Performance Metrics\\n- **Model Accuracy**: 94.3%\\n- **Production Deployment Rate**: 85%\\n- **Research Publications**: 5\\n- **Peer Review Rating**: 4.9/5'), 'fdbb64dd-d811-45d0-8c64-4bc7d189b9b7': Document(id='fdbb64dd-d811-45d0-8c64-4bc7d189b9b7', metadata={'source': 'data\\\\developers\\\\john_smith.md', 'doc_type': 'developers'}, page_content='# Developer Profile: John Smith\\n\\n## Personal Information\\n- **Name**: John Smith\\n- **Position**: Senior Software Engineer\\n- **Email**: john.smith@example.com\\n- **Location**: Seattle, WA\\n- **Years of Experience**: 8\\n\\n## Skills\\n- **Programming Languages**: JavaScript, TypeScript, Python, Java\\n- **Frameworks/Libraries**: React, Node.js, Express, Django\\n- **Cloud Platforms**: AWS, Azure\\n- **Other Tools**: Docker, Kubernetes, Git, CI/CD\\n\\n## Projects\\n- Lead developer on CloudSync project\\n- Backend architect for MobileConnect platform\\n- Contributing developer to DataViz analytics suite\\n\\n## Education\\n- M.S. Computer Science, University of Washington, 2015\\n- B.S. Computer Engineering, MIT, 2012\\n\\n## Certifications\\n- AWS Certified Solutions Architect\\n- Microsoft Certified: Azure Developer Associate\\n- Docker Certified Associate\\n\\n## Performance Metrics\\n- **Code Quality Score**: 95/100\\n- **On-time Delivery Rate**: 98%\\n- **Peer Review Rating**: 4.8/5\\n- **Bug Resolution Time**: Avg. 1.2 days'), 'a690d2da-f4f1-4771-8612-75f8c575a617': Document(id='a690d2da-f4f1-4771-8612-75f8c575a617', metadata={'source': 'data\\\\developers\\\\raj_patel.md', 'doc_type': 'developers'}, page_content='# Developer Profile: Raj Patel\\n\\n## Personal Information\\n- **Name**: Raj Patel\\n- **Position**: DevOps Engineer\\n- **Email**: raj.patel@example.com\\n- **Location**: Austin, TX\\n- **Years of Experience**: 6\\n\\n## Skills\\n- **Programming Languages**: Python, Go, Bash, Ruby\\n- **Infrastructure**: Terraform, Ansible, Puppet\\n- **Cloud Platforms**: AWS, GCP, Azure\\n- **Other Tools**: Jenkins, GitHub Actions, ArgoCD, Prometheus, Grafana\\n\\n## Projects\\n- Lead architect for CloudInfra automation project\\n- DevOps specialist for MicroServices migration\\n- Creator of internal monitoring dashboard\\n\\n## Education\\n- M.S. Computer Science, University of Texas at Austin, 2016\\n- B.Tech. Information Technology, Indian Institute of Technology, 2014\\n\\n## Certifications\\n- Certified Kubernetes Administrator (CKA)\\n- AWS Certified DevOps Engineer - Professional\\n- Terraform Associate\\n- Azure DevOps Engineer Expert\\n\\n## Performance Metrics\\n- **Infrastructure Uptime**: 99.98%\\n- **Deployment Success Rate**: 99.5%\\n- **Mean Time to Recovery**: 15 minutes\\n- **Peer Review Rating**: 4.7/5'), '33e91287-b503-45a9-be7a-072a1eda703e': Document(id='33e91287-b503-45a9-be7a-072a1eda703e', metadata={'source': 'data\\\\developers\\\\sarah_johnson.md', 'doc_type': 'developers'}, page_content='# Developer Profile: Sarah Johnson\\n\\n## Personal Information\\n- **Name**: Sarah Johnson\\n- **Position**: Frontend Developer\\n- **Email**: sarah.johnson@example.com\\n- **Location**: Portland, OR\\n- **Years of Experience**: 5\\n\\n## Skills\\n- **Programming Languages**: JavaScript, TypeScript, HTML, CSS\\n- **Frameworks/Libraries**: React, Vue.js, Angular, Tailwind CSS\\n- **Cloud Platforms**: Netlify, Vercel\\n- **Other Tools**: Webpack, Jest, Cypress, Git\\n\\n## Projects\\n- UI/UX lead for CustomerPortal project\\n- Frontend developer for HealthTrack application\\n- Creator of InternalDashboard component library\\n\\n## Education\\n- B.S. Web Development, Oregon State University, 2017\\n\\n## Certifications\\n- Google UX Design Professional Certificate\\n- React Certification - Frontend Masters\\n- Accessibility Specialist Certification\\n\\n## Performance Metrics\\n- **Code Quality Score**: 92/100\\n- **On-time Delivery Rate**: 95%\\n- **Peer Review Rating**: 4.6/5\\n- **Bug Resolution Time**: Avg. 1.5 days'), '4d3d6f62-35b9-460e-8101-c9d370fb30c4': Document(id='4d3d6f62-35b9-460e-8101-c9d370fb30c4', metadata={'source': 'data\\\\projects\\\\cloudsync.md', 'doc_type': 'projects'}, page_content='# Project: CloudSync\\n\\n## Overview\\nCloudSync is a cloud-based file synchronization and sharing platform designed for enterprise use. It enables seamless collaboration across teams while maintaining strict security and compliance standards.\\n\\n## Technical Details\\n- **Stack**: React, Node.js, MongoDB, Redis\\n- **Cloud Provider**: AWS\\n- **Architecture**: Microservices\\n- **APIs**: REST, GraphQL\\n- **Authentication**: OAuth 2.0, SAML\\n\\n## Team\\n- **Project Lead**: John Smith\\n- **Frontend Developers**: Sarah Johnson, Miguel Lopez\\n- **Backend Developers**: John Smith, Lisa Wong\\n- **DevOps**: Raj Patel\\n- **QA**: Priya Mehta\\n\\n## Timeline\\n- **Started**: January 2022\\n- **Beta Launch**: August 2022\\n- **Production Release**: November 2022\\n- **Current Version**: 2.3.0\\n- **Next Milestone**: Multi-region support (Q3 2023)\\n\\n## Key Metrics\\n- **Code Coverage**: 87%\\n- **User Base**: 15,000+\\n- **Storage Managed**: 50TB\\n- **Availability SLA**: 99.95%\\n- **Average Response Time**: 120ms\\n\\n## Challenges\\n- Implementing end-to-end encryption while maintaining search functionality\\n- Scaling synchronization engine to handle enterprise workloads\\n- Cross-platform compatibility issues with desktop clients'), 'fcb818eb-bb24-4662-93d3-29aa39957064': Document(id='fcb818eb-bb24-4662-93d3-29aa39957064', metadata={'source': 'data\\\\projects\\\\dataviz.md', 'doc_type': 'projects'}, page_content='# Project: DataViz\\n\\n## Overview\\nDataViz is an enterprise data visualization and analytics platform that transforms complex datasets into interactive, insightful dashboards. It supports real-time data processing and offers customizable visualization components for business intelligence.\\n\\n## Technical Details\\n- **Stack**: Vue.js, D3.js, FastAPI, Elasticsearch\\n- **Cloud Provider**: GCP\\n- **Architecture**: Event-driven\\n- **APIs**: REST, WebSockets\\n- **Authentication**: OAuth 2.0, API Keys\\n\\n## Team\\n- **Project Lead**: Lisa Wong\\n- **Frontend Developers**: Sarah Johnson, Tyler Adams\\n- **Backend Developers**: John Smith, Eric Johnson\\n- **Data Engineers**: Alex Chen, Michael Brown\\n- **QA**: David Kim\\n\\n## Timeline\\n- **Started**: September 2021\\n- **Beta Launch**: May 2022\\n- **Production Release**: August 2022\\n- **Current Version**: 3.1.2\\n- **Next Milestone**: Advanced ML-powered forecasting (Q2 2023)\\n\\n## Key Metrics\\n- **Code Coverage**: 89%\\n- **Enterprise Clients**: 42\\n- **Dashboards Created**: 3,800+\\n- **Avg. Dashboard Load Time**: 1.2s\\n- **Data Processed Daily**: 8TB\\n\\n## Challenges\\n- Maintaining performance with large datasets\\n- Creating intuitive UX for complex data operations\\n- Implementing real-time collaboration features'), 'ea882430-e6be-43aa-8dcb-be3f4089add5': Document(id='ea882430-e6be-43aa-8dcb-be3f4089add5', metadata={'source': 'data\\\\projects\\\\fraud_detection.md', 'doc_type': 'projects'}, page_content='# Project: FraudDetection\\n\\n## Overview\\nFraudDetection is an AI-powered system that identifies and prevents fraudulent transactions in real-time. The platform uses machine learning models to analyze transaction patterns and detect anomalies across multiple financial channels.\\n\\n## Technical Details\\n- **Stack**: Python, TensorFlow, Spark, Kafka, PostgreSQL\\n- **Cloud Provider**: AWS\\n- **Architecture**: Lambda architecture (batch + stream processing)\\n- **APIs**: REST, Apache Avro\\n- **ML Models**: XGBoost, Neural Networks\\n\\n## Team\\n- **Project Lead**: Michael Brown\\n- **ML Engineers**: Alex Chen, Tanya Sharma\\n- **Data Engineers**: Lisa Wong, Eric Johnson\\n- **DevOps**: Raj Patel\\n- **Security Specialists**: David Kim, Maria Rodriguez\\n\\n## Timeline\\n- **Started**: July 2021\\n- **Pilot Launch**: March 2022\\n- **Production Release**: June 2022\\n- **Current Version**: 2.4.1\\n- **Next Milestone**: Advanced anomaly detection (Q3 2023)\\n\\n## Key Metrics\\n- **Fraud Detection Rate**: 96.3%\\n- **False Positive Rate**: 2.1%\\n- **Avg. Detection Time**: 285ms\\n- **Daily Transactions Processed**: 4.5 million\\n- **Cost Savings**: $2.8M annual fraud prevention\\n\\n## Challenges\\n- Balancing false positives with detection sensitivity\\n- Processing high-volume transactions in real-time\\n- Adapting to evolving fraud techniques'), 'e2902804-b559-462a-8712-f70af76ea976': Document(id='e2902804-b559-462a-8712-f70af76ea976', metadata={'source': 'data\\\\projects\\\\healthtrack.md', 'doc_type': 'projects'}, page_content='# Project: HealthTrack\\n\\n## Overview\\nHealthTrack is a mobile and web application for personal health monitoring, allowing users to track fitness activities, nutrition, and health metrics. The platform integrates with various wearable devices and provides personalized insights.\\n\\n## Technical Details\\n- **Stack**: React Native, Flask, PostgreSQL\\n- **Cloud Provider**: Azure\\n- **Architecture**: API-First Design\\n- **APIs**: REST\\n- **Authentication**: JWT, OAuth 2.0\\n\\n## Team\\n- **Project Lead**: Maria Rodriguez\\n- **Frontend Developers**: Sarah Johnson, Kevin Williams\\n- **Backend Developers**: Tanya Sharma, Eric Johnson\\n- **Mobile Developer**: James Wilson\\n- **Data Scientist**: Alex Chen\\n\\n## Timeline\\n- **Started**: March 2022\\n- **Beta Launch**: October 2022\\n- **Production Release**: February 2023\\n- **Current Version**: 1.8.5\\n- **Next Milestone**: AI-powered health insights (Q4 2023)\\n\\n## Key Metrics\\n- **Code Coverage**: 82%\\n- **User Base**: 75,000+\\n- **Active Daily Users**: 28,000\\n- **App Store Rating**: 4.7/5\\n- **Crash Rate**: 0.2%\\n\\n## Challenges\\n- Ensuring HIPAA compliance and data security\\n- Cross-platform performance optimization\\n- Integration with diverse wearable device APIs'), '116b5878-09a1-495f-987c-05384bc9f293': Document(id='116b5878-09a1-495f-987c-05384bc9f293', metadata={'source': 'data\\\\projects\\\\microservices.md', 'doc_type': 'projects'}, page_content=\"# Project: MicroServices Migration\\n\\n## Overview\\nA strategic initiative to decompose the company's monolithic legacy application into a modern microservices architecture. This project aims to improve scalability, development agility, and system resilience.\\n\\n## Technical Details\\n- **Stack**: Spring Boot, Kotlin, gRPC, PostgreSQL, MongoDB\\n- **Cloud Provider**: AWS, Azure (multi-cloud)\\n- **Architecture**: Domain-driven microservices\\n- **Communication**: Event-driven (Kafka)\\n- **Deployment**: Kubernetes\\n\\n## Team\\n- **Project Lead**: Eric Johnson\\n- **Backend Architects**: John Smith, Tanya Sharma\\n- **DevOps Engineers**: Raj Patel, Chris Martinez\\n- **Migration Specialists**: Lisa Wong, David Kim\\n- **QA**: Priya Mehta, James Wilson\\n\\n## Timeline\\n- **Started**: November 2021\\n- **Phase 1 Completion**: July 2022\\n- **Phase 2 Completion**: January 2023\\n- **Current Status**: Phase 3 (70% complete)\\n- **Expected Completion**: Q4 2023\\n\\n## Key Metrics\\n- **Services Migrated**: 18/25\\n- **Legacy Codebase Reduction**: 68%\\n- **Deployment Frequency Increase**: 450%\\n- **Mean Time to Recovery**: Reduced from 4 hours to 22 minutes\\n- **Infrastructure Cost Reduction**: 32%\\n\\n## Challenges\\n- Maintaining service integrity during transition periods\\n- Managing complex service dependencies\\n- Ensuring consistent observability across services\")}\n"
     ]
    }
   ],
   "source": [
    "faiss_collection = faiss_vectorstore.docstore\n",
    "print(len((faiss_collection.__dict__)['_dict']))\n",
    "faiss_collection = (faiss_collection.__dict__)['_dict']\n",
    "\n",
    "print(faiss_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ebaafc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the different projects mentioned in the documents?\n",
      "Answer: The documents mention three separate projects:\n",
      "\n",
      "1. **Project: MicroServices Migration**: A strategic initiative to decompose the company's monolithic legacy application into a modern microservices architecture.\n",
      "2. **Project: FraudDetection**: An AI-powered system that identifies and prevents fraudulent transactions in real-time, using machine learning models and a Lambda architecture.\n",
      "3. **Business Impact: CloudSync**: A project that transformed internal collaboration workflows and enhanced security posture, resulting in significant productivity gains and cost reductions.\n",
      "\n",
      "Additionally, there are two separate business impact documents:\n",
      "\n",
      "1. **Business Impact: MicroServices Migration**\n",
      "2. **Business Impact: CloudSync**\n",
      "\n",
      "Lastly, there is a generic document titled \"Future Business Opportunities\" which mentions opportunities for the three projects mentioned earlier.\n"
     ]
    }
   ],
   "source": [
    "# Create a RAG chain using Ollama LLM and FAISS vector store\n",
    "ollama_llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "# Create memory and chain with the loaded vector store\n",
    "ollama_memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "ollama_retriever = faiss_vectorstore.as_retriever()\n",
    "ollama_rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=ollama_llm, \n",
    "    memory=ollama_memory, \n",
    "    retriever=ollama_retriever\n",
    ")\n",
    "\n",
    "# Test the open-source RAG chain\n",
    "query = \"What are the different projects mentioned in the documents?\"\n",
    "result = ollama_rag_chain.invoke({\"question\": query})\n",
    "print('Question:', query)\n",
    "print('Answer:', result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e11a69",
   "metadata": {},
   "source": [
    "#### RAG without Langchain: Ollma + SentenceTransformer Embedding\n",
    "Instead of relying on the langchain for building the RAG chain, we can instead do it ourselves using some code to manage the below things:\n",
    "1. Interactions with the vector store - ChromaDB in this case\n",
    "2. Filling the context of user prompt by doing a semantic search from the chromadb for the user query\n",
    "3. Then we use this augmented user prompt with the context information and then use the classic llm api to get the chat completion response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7a820",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
